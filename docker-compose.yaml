services:
  autoround-quantizer:
    # Builds the image from the local Dockerfile
    build: .

    # --- GPU Allocation ---
    # Use the modern Container Device Interface (CDI) to reserve GPU resources.
    deploy:
      resources:
        reservations:
          devices:
            - driver: cdi
              # 'all' uses all available GPUs. Can be specific, e.g., ['0', '1']
              device_ids:
                - 'nvidia.com/gpu=all'
              capabilities:
                - gpu

    # --- Job Configuration ---
    # Environment variables are passed to the run_advanced.py script.
    environment:
      # Model from Hugging Face or path to a local model folder.
      MODEL_ID: "Qwen/Qwen3-0.6B"
      # Quantization recipe. Options: auto-round, auto-round-best, auto-round-light
      RECIPE: "auto-round"
      # Target bits for quantization.
      BITS: "4"
      # Quantization group size.
      GROUP_SIZE: "128"
      # Output formats. Can be a comma-separated list: "auto_awq,auto_gptq,auto_round"
      FORMATS: "auto_awq"
      # Set to "true" to enable low VRAM mode. Essential for large models.
      LOW_MEM: "true"
      # Increases download timeout for large files on unstable connections.
      HF_HUB_ETAG_TIMEOUT: "120"
      # Quantization method. Options: auto-round, quanto
      QUANTIZATION_METHOD: "auto-round"

      # --- Upload Control ---
      # Set to "true" to enable compression and/or uploading after quantization.
      UPLOAD_AFTER_DONE: "false"
      # Determines the post-quantization action.
      # "zipline": Compresses, uploads to Zipline, then deletes the local archive.
      # "local": Compresses and keeps the local archive.
      UPLOAD_TYPE: "local"

      # --- Credentials (only needed if uploading) ---
      # Your Zipline instance domain (e.g., files.example.com).
      ZIPLINE_DOMAIN: "your-files.getsilly.org"
      # Your Zipline authorization token.
      ZIPLINE_TOKEN: ""

    # --- Persistent Storage ---
    volumes:
      # Maps the container's output directory to a local folder.
      - ./autoround_output:/app/output
      # Persists the Hugging Face model cache to the host to avoid re-downloads.
      - ./hf_cache:/root/.cache/huggingface

    # Increases shared memory size. Critical for preventing crashes with large models.
    shm_size: 16gb
